{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T14:40:35.998080300Z",
     "start_time": "2023-07-17T14:40:24.700998100Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tziam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from collections import Counter\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "ExecuteTime": {
     "end_time": "2023-07-17T14:40:58.154373300Z",
     "start_time": "2023-07-17T14:40:58.020484800Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Datasets/train.csv\")\n",
    "test_data = pd.read_csv(\"Datasets/test.csv\")\n",
    "sample_submission = pd.read_csv(\"Datasets/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T14:40:59.156134200Z",
     "start_time": "2023-07-17T14:40:59.103548800Z"
    }
   },
   "outputs": [],
   "source": [
    "data.dropna(axis = 0, how ='any',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T14:41:00.139523100Z",
     "start_time": "2023-07-17T14:41:00.107880700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'positive', 'negative', 'neutral'}\n"
     ]
    },
    {
     "data": {
      "text/plain": "       textID                                               text  \\\n0  cb774db0d1                I`d have responded, if I were going   \n1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n2  088c60f138                          my boss is bullying me...   \n3  9642c003ef                     what interview! leave me alone   \n4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n5  28b57f3990  http://www.dothebouncy.com/smf - some shameles...   \n6  6e0c6d75b1  2am feedings for the baby are fun when he is a...   \n7  50e14c0bb8                                         Soooo high   \n8  e050245fbd                                        Both of you   \n9  fc2cbefa9d   Journey!? Wow... u just became cooler.  hehe....   \n\n                                       selected_text sentiment  \n0                I`d have responded, if I were going   neutral  \n1                                           Sooo SAD  negative  \n2                                        bullying me  negative  \n3                                     leave me alone  negative  \n4                                      Sons of ****,  negative  \n5  http://www.dothebouncy.com/smf - some shameles...   neutral  \n6                                                fun  positive  \n7                                         Soooo high   neutral  \n8                                        Both of you   neutral  \n9                       Wow... u just became cooler.  positive  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>text</th>\n      <th>selected_text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cb774db0d1</td>\n      <td>I`d have responded, if I were going</td>\n      <td>I`d have responded, if I were going</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>549e992a42</td>\n      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n      <td>Sooo SAD</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>088c60f138</td>\n      <td>my boss is bullying me...</td>\n      <td>bullying me</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9642c003ef</td>\n      <td>what interview! leave me alone</td>\n      <td>leave me alone</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>358bd9e861</td>\n      <td>Sons of ****, why couldn`t they put them on t...</td>\n      <td>Sons of ****,</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>28b57f3990</td>\n      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6e0c6d75b1</td>\n      <td>2am feedings for the baby are fun when he is a...</td>\n      <td>fun</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>50e14c0bb8</td>\n      <td>Soooo high</td>\n      <td>Soooo high</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>e050245fbd</td>\n      <td>Both of you</td>\n      <td>Both of you</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>fc2cbefa9d</td>\n      <td>Journey!? Wow... u just became cooler.  hehe....</td>\n      <td>Wow... u just became cooler.</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(set(data['sentiment']))\n",
    "y=data['selected_text']\n",
    "X=data\n",
    "X.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T14:41:01.977946700Z",
     "start_time": "2023-07-17T14:41:01.954968500Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T14:41:03.344138800Z",
     "start_time": "2023-07-17T14:41:03.329994400Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T14:41:04.282785100Z",
     "start_time": "2023-07-17T14:41:04.251370800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Returns a specific column from a DataFrame based on the specified sentiment.\n",
    "def get_column_from_sentiment(sentiment,column):\n",
    "    selected_data=X_train.loc[X_train['sentiment'] == sentiment]\n",
    "    return selected_data[column]\n",
    "\n",
    "# Calculates the word count and frequency of each word in a given column.\n",
    "def get_word_count(column):\n",
    "    all_text=\"\".join(column)\n",
    "    all_text=clean(all_text)\n",
    "    all_text=all_text.split(' ')\n",
    "    all_text = list(filter(None, all_text))\n",
    "    total=len(all_text)\n",
    "    counts = Counter(all_text)\n",
    "    for item, count in counts.items():\n",
    "        counts[item] /= total\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T14:41:10.790049100Z",
     "start_time": "2023-07-17T14:41:05.048913400Z"
    }
   },
   "outputs": [],
   "source": [
    "text=X_train['text']\n",
    "selected_text=y_train\n",
    "\n",
    "# Join the text and selected text into single strings\n",
    "text=\"\".join(text)\n",
    "selected_text=\"\".join(selected_text)\n",
    "\n",
    "# Preprocess the text and selected text\n",
    "text=clean(text)\n",
    "selected_text=clean(selected_text)\n",
    "\n",
    "# Split the text and selected text into individual words\n",
    "text=text.split(' ')\n",
    "selected_text=selected_text.split(' ')\n",
    "\n",
    "# Remove any empty strings from the lists\n",
    "text = list(filter(None, text))\n",
    "selected_text = list(filter(None, selected_text))\n",
    "\n",
    "# Calculate the word count and frequency in the text\n",
    "text_counter = get_word_count(text)\n",
    "\n",
    "# Find the words present in the text but not in the selected text\n",
    "list_difference = [item for item in text if item not in selected_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T14:41:14.767692500Z",
     "start_time": "2023-07-17T14:41:14.758076600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Converts a column in a DataFrame to a list of preprocessed and filtered words.\n",
    "def column_to_list(column):\n",
    "    text=\"\".join(column)\n",
    "    text=clean(text)\n",
    "    text=text.split(' ')\n",
    "    text = list(filter(None, text))\n",
    "    return text\n",
    "\n",
    "# Finds the difference between two columns by comparing their word lists.\n",
    "def get_list_difference(column_mother,column_child):\n",
    "    list_mother=column_to_list(column_mother)\n",
    "    list_child=column_to_list(column_child)\n",
    "    list_difference = [item for item in list_mother if item not in list_child]\n",
    "    return list_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T14:41:16.485982900Z",
     "start_time": "2023-07-17T14:41:16.218394800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Calculates the number of words in a sentence.\n",
    "def get_length(sentence):\n",
    "    words=sentence.split(' ')\n",
    "    words = list(filter(None, words))\n",
    "    return len(words)\n",
    "\n",
    "# Calculates the average length of sentences in a column.\n",
    "def average_length(column):\n",
    "    length=[]\n",
    "    for i in range(len(column)):\n",
    "        sentence=column.iloc[i]\n",
    "        length.append(get_length(sentence))\n",
    "    print(np.max(length))\n",
    "print(average_length(X_train['selected_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T14:41:19.973141400Z",
     "start_time": "2023-07-17T14:41:17.472800200Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\\n       'positive', 'negative', 'negative', 'negative',\\n       ...\\n       'positive', 'positive', 'neutral', 'positive', 'negative', 'neutral',\\n       'positive', 'negative', 'neutral', 'neutral'],\\n      dtype='object', length=23358)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Get the word counts for each sentiment category\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m positive_counter\u001B[38;5;241m=\u001B[39mget_word_count(\u001B[43mget_column_from_sentiment\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpositive\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msentiment\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m      3\u001B[0m negative_counter\u001B[38;5;241m=\u001B[39mget_word_count(get_column_from_sentiment(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnegative\u001B[39m\u001B[38;5;124m'\u001B[39m, X_train[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msentiment\u001B[39m\u001B[38;5;124m'\u001B[39m]))\n\u001B[0;32m      4\u001B[0m neutral_counter\u001B[38;5;241m=\u001B[39mget_word_count(get_column_from_sentiment(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mneutral\u001B[39m\u001B[38;5;124m'\u001B[39m, X_train[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msentiment\u001B[39m\u001B[38;5;124m'\u001B[39m]))\n",
      "Cell \u001B[1;32mIn[7], line 4\u001B[0m, in \u001B[0;36mget_column_from_sentiment\u001B[1;34m(sentiment, column)\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_column_from_sentiment\u001B[39m(sentiment,column):\n\u001B[0;32m      3\u001B[0m     selected_data\u001B[38;5;241m=\u001B[39mX_train\u001B[38;5;241m.\u001B[39mloc[X_train[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msentiment\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m sentiment]\n\u001B[1;32m----> 4\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mselected_data\u001B[49m\u001B[43m[\u001B[49m\u001B[43mcolumn\u001B[49m\u001B[43m]\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3813\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3811\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_iterator(key):\n\u001B[0;32m   3812\u001B[0m         key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(key)\n\u001B[1;32m-> 3813\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_indexer_strict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcolumns\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m   3815\u001B[0m \u001B[38;5;66;03m# take() does not accept boolean indexers\u001B[39;00m\n\u001B[0;32m   3816\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(indexer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mbool\u001B[39m:\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6070\u001B[0m, in \u001B[0;36mIndex._get_indexer_strict\u001B[1;34m(self, key, axis_name)\u001B[0m\n\u001B[0;32m   6067\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   6068\u001B[0m     keyarr, indexer, new_indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reindex_non_unique(keyarr)\n\u001B[1;32m-> 6070\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_raise_if_missing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkeyarr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   6072\u001B[0m keyarr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtake(indexer)\n\u001B[0;32m   6073\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, Index):\n\u001B[0;32m   6074\u001B[0m     \u001B[38;5;66;03m# GH 42790 - Preserve name from an Index\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6130\u001B[0m, in \u001B[0;36mIndex._raise_if_missing\u001B[1;34m(self, key, indexer, axis_name)\u001B[0m\n\u001B[0;32m   6128\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m use_interval_msg:\n\u001B[0;32m   6129\u001B[0m         key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(key)\n\u001B[1;32m-> 6130\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNone of [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m] are in the [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00maxis_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   6132\u001B[0m not_found \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(ensure_index(key)[missing_mask\u001B[38;5;241m.\u001B[39mnonzero()[\u001B[38;5;241m0\u001B[39m]]\u001B[38;5;241m.\u001B[39munique())\n\u001B[0;32m   6133\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnot_found\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not in index\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mKeyError\u001B[0m: \"None of [Index(['neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\\n       'positive', 'negative', 'negative', 'negative',\\n       ...\\n       'positive', 'positive', 'neutral', 'positive', 'negative', 'neutral',\\n       'positive', 'negative', 'neutral', 'neutral'],\\n      dtype='object', length=23358)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# Get the word counts for each sentiment category\n",
    "positive_counter=get_word_count(get_column_from_sentiment('positive', X_train['sentiment']))\n",
    "negative_counter=get_word_count(get_column_from_sentiment('negative', X_train['sentiment']))\n",
    "neutral_counter=get_word_count(get_column_from_sentiment('neutral', X_train['sentiment']))\n",
    "\n",
    "# Get the lists of words for each sentiment category\n",
    "positive_list=list(positive_counter.keys())\n",
    "negative_list=list(negative_counter.keys())\n",
    "neutral_list=list(neutral_counter.keys())\n",
    "\n",
    "# Find the words that are common across all sentiment categories\n",
    "common_elements = list(set(positive_list).intersection(set(negative_list)))\n",
    "common_elements = list(set(common_elements).intersection(set(neutral_list)))\n",
    "\n",
    "# Initialize an empty list to store the words that meet the specified conditions\n",
    "no_words=[]\n",
    "# neighbor is a threshold parameter for comparing word frequencies\n",
    "neighbor=0\n",
    "\n",
    "# Iterate over the common words and check the conditions using sentiment frequencies\n",
    "for w in common_elements:\n",
    "    if (positive_counter[w]> (1-neighbor)*negative_counter[w] and positive_counter[w]< (1+neighbor)*negative_counter[w]) and (neutral_counter[w]> (1-neighbor)*negative_counter[w] and neutral_counter[w]< (1+neighbor)*negative_counter[w]):\n",
    "        no_words.append(w)\n",
    "print(no_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T14:41:22.156917100Z",
     "start_time": "2023-07-17T14:41:21.901798100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compares the word frequencies between a parent column and a child column.\n",
    "def freq_comparison(column_parent,column_child):\n",
    "    parent_count=get_word_count(column_parent)\n",
    "    child_count=get_word_count(column_child)\n",
    "    remove_list=[]\n",
    "    for w in parent_count:\n",
    "        if w not in child_count:\n",
    "            remove_list.append(w)\n",
    "        elif parent_count[w] > 4* child_count[w]:\n",
    "            remove_list.append(w)\n",
    "    return remove_list\n",
    "\n",
    "positive=X_train.loc[X_train['sentiment'] == 'positive']\n",
    "remove_list_positive=freq_comparison(positive['text'],positive['selected_text'])\n",
    "\n",
    "neutral=X_train.loc[X_train['sentiment'] == 'neutral']\n",
    "remove_list_neutral=freq_comparison(neutral['text'],neutral['selected_text'])\n",
    "\n",
    "negative=X_train.loc[X_train['sentiment'] == 'negative']\n",
    "remove_list_negative=freq_comparison(negative['text'],negative['selected_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T14:41:24.292439100Z",
     "start_time": "2023-07-17T14:41:23.236087400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999\n"
     ]
    }
   ],
   "source": [
    "# Create a subset of the DataFrame containing only positive sentiment rows\n",
    "positive=X_train.loc[X_train['sentiment'] == 'positive']\n",
    "# Calculate the list of words that are present in the 'text' column but not in the 'selected_text' column of the positive subset\n",
    "remove_list_positive=get_list_difference(positive['text'],positive['selected_text'])\n",
    "print(len(set(remove_list_positive)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T14:41:28.356137500Z",
     "start_time": "2023-07-17T14:41:25.257324Z"
    }
   },
   "outputs": [],
   "source": [
    "neutral=X_train.loc[X_train['sentiment'] == 'neutral']\n",
    "remove_list_neutral=get_list_difference(neutral['text'],neutral['selected_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T14:41:33.333350900Z",
     "start_time": "2023-07-17T14:41:29.748077800Z"
    }
   },
   "outputs": [],
   "source": [
    "negative=X_train.loc[X_train['sentiment'] == 'negative']\n",
    "remove_list_negative=get_list_difference(negative['text'],negative['selected_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T14:41:35.240135200Z",
     "start_time": "2023-07-17T14:41:34.769152400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6695\n"
     ]
    }
   ],
   "source": [
    "print(len(remove_list_negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T14:41:36.569527300Z",
     "start_time": "2023-07-17T14:41:36.538257600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predicts the selected words in a given sentence based on the specified sentiment.\n",
    "def predict(sentence,sentiment):\n",
    "    # Preprocess the input sentence using the `preprocess_tweet_text` function\n",
    "    sentence=clean(sentence)\n",
    "    # Convert the preprocessed sentence to lowercase and split into individual words\n",
    "    words=sentence.lower().split()\n",
    "\n",
    "    # Determine the appropriate remove_list based on the specified sentiment\n",
    "    if sentiment=='positive':\n",
    "        remove_list=remove_list_positive\n",
    "    if sentiment=='neutral':\n",
    "        remove_list=[]\n",
    "    if sentiment=='negative':\n",
    "        remove_list=remove_list_negative\n",
    "\n",
    "    # Filter the words in the sentence by removing the ones present in the remove_list\n",
    "    selected_words=[w for w in words if w not in remove_list]\n",
    "    # Join the selected words back into a single string\n",
    "    selected_words=' '.join(selected_words)\n",
    "\n",
    "    return selected_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T14:41:38.710907100Z",
     "start_time": "2023-07-17T14:41:38.695197900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculates the Jaccard similarity coefficient between two strings.\n",
    "def jaccard(str1, str2):\n",
    "    # Convert the first string to lowercase and split it into individual words. Create a set from the words.\n",
    "    a = set(str1.lower().split())\n",
    "    # Convert the second string to lowercase and split it into individual words. Create a set from the words.\n",
    "    b = set(str2.lower().split())\n",
    "    # Find the intersection of the two sets of words.\n",
    "    c = a.intersection(b)\n",
    "\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T14:41:42.231744Z",
     "start_time": "2023-07-17T14:41:39.851726700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5729263876589449\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store the Jaccard similarity coefficients\n",
    "jac=[]\n",
    "\n",
    "# Iterate over rows to make predictions\n",
    "for i in range(X_test.shape[0]): \n",
    "    sentence=X_test['text'].iloc[i]\n",
    "    sentiment=X_test['sentiment'].iloc[i]\n",
    "    selected_sentence=y_test.iloc[i]\n",
    "    if len(sentence.split())>5:\n",
    "        prediction=predict(sentence,sentiment)\n",
    "    else:\n",
    "        prediction=sentence\n",
    "    jac.append(jaccard(selected_sentence,prediction))\n",
    "\n",
    "print(np.mean(jac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T14:41:43.138134700Z",
     "start_time": "2023-07-17T14:41:43.096846100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "           textID                                               text  \\\n1976   a8296482f1  @ the San Antonio Missions game waitressing. N...   \n14522  1d450fad81  Had an interesting evening amongst homeless pe...   \n16048  3e3a0af796   Try being in AZ again brooke, Omg you cant ev...   \n16981  f3bd26a6ff         what happened? I missed 4 hours of updates   \n25085  3a70785fec    You cna get em for about ï¿½17 but I`ve got ...   \n\n                                           selected_text sentiment  \n1976   @ the San Antonio Missions game waitressing. N...   neutral  \n14522                                        interesting  positive  \n16048  Try being in AZ again brooke, Omg you cant eve...  negative  \n16981         what happened? I missed 4 hours of updates   neutral  \n25085  You cna get em for about ï¿½17 but I`ve got on...   neutral  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>text</th>\n      <th>selected_text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1976</th>\n      <td>a8296482f1</td>\n      <td>@ the San Antonio Missions game waitressing. N...</td>\n      <td>@ the San Antonio Missions game waitressing. N...</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>14522</th>\n      <td>1d450fad81</td>\n      <td>Had an interesting evening amongst homeless pe...</td>\n      <td>interesting</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>16048</th>\n      <td>3e3a0af796</td>\n      <td>Try being in AZ again brooke, Omg you cant ev...</td>\n      <td>Try being in AZ again brooke, Omg you cant eve...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>16981</th>\n      <td>f3bd26a6ff</td>\n      <td>what happened? I missed 4 hours of updates</td>\n      <td>what happened? I missed 4 hours of updates</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>25085</th>\n      <td>3a70785fec</td>\n      <td>You cna get em for about ï¿½17 but I`ve got ...</td>\n      <td>You cna get em for about ï¿½17 but I`ve got on...</td>\n      <td>neutral</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T14:41:46.737078500Z",
     "start_time": "2023-07-17T14:41:44.868816300Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_submission=sample_submission.drop('selected_text',axis=1)\n",
    "for i in range(test_data.shape[0]):\n",
    "    sentence=test_data['text'].iloc[i]\n",
    "    sentiment = test_data['sentiment'].iloc[i]\n",
    "    if len(sentence.split())>2:\n",
    "        prediction=predict(sentence, sentiment)\n",
    "    else:\n",
    "        prediction=sentence\n",
    "    sample_submission.at[i,'selected_text']=prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T14:41:52.037482400Z",
     "start_time": "2023-07-17T14:41:51.982295400Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_submission.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T14:41:55.239395400Z",
     "start_time": "2023-07-17T14:41:55.222570300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       textID                                      selected_text\n0  f87dea47db                            last session of the day\n1  96d74cb729  shanghai is also really exciting (precisely --...\n2  eee518ae67  recession hit veronique branquinho, she has to...\n3  01082688c6                                        happy bday!\n4  33987a8ee5                                      - i like it!!",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>selected_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>f87dea47db</td>\n      <td>last session of the day</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>96d74cb729</td>\n      <td>shanghai is also really exciting (precisely --...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>eee518ae67</td>\n      <td>recession hit veronique branquinho, she has to...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>01082688c6</td>\n      <td>happy bday!</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>33987a8ee5</td>\n      <td>- i like it!!</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
